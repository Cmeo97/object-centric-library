# @package _global_

defaults:
  - _base

batch_size: 64
trainer:
  _target_: models.vmnn.trainer.VMNNTrainer
  steps: 400 #500_000
  use_warmup_lr: true
  warmup_steps: 10 #10_000
  use_exp_decay: true
  exp_decay_rate: 0.5
  exp_decay_steps: 100 #100_000

  optimizer_config:
    alg: Adam
    lr: 0.0007

model:
  _target_: models.vmnn_video.model.vmnnAE
  name: vmnn_video
  num_slots: ${dataset.max_num_objects}
  latent_size: 64
  beta: 4
  encoder_params:
    channels: [32, 32, 32, 32]
    kernels: [5, 5, 5, 5]
    paddings: [2, 2, 2, 2]
    strides: [1, 1, 1, 1]
  decoder_params:
    conv_transposes: false
    channels: [32, 32, 32, 4]
    kernels: [5, 5, 5, 3]
    strides: [1, 1, 1, 1]
    paddings: [2, 2, 2, 1]
    output_paddings: [0, 0, 0, 0]
    activations: [relu, relu, relu, null]
  vmnn_params:
    communication: 'None'
    latent_size: 64
    comm_key_size: 32
    comm_value_size: 32
    num_comm_heads: 1
    n_SK_slots: 2
    latent_layers: 1
    hidden_size: 64
    num_slots: ${dataset.max_num_objects}
    dynamics: 'AD'
    h_key_size: 64
    z_key_size: 64
    num_grus: 1
    num_dynamics_heads: 1
    loss : 'disentangled_beta_vae'

  attention_iters: 3
  mlp_size: 128
  eps: 1e-8
  h_broadcast: ${dataset.height}
  w_broadcast: ${dataset.width}
  